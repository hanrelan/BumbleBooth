# Stable Diffusion using BumbleBee

```elixir
# This should be set appropriately for the system
# eg. cuda118 for a machine with a GPU and CUDA 11.8+
IO.puts(System.get_env("XLA_TARGET"))

Mix.install(
  [
    {:bumblebee, github: "elixir-nx/bumblebee", branch: "main", override: true},
    {:exla, ">= 0.0.0"},
    {:kino_bumblebee, "~> 0.1.0"}
  ],
  config: [nx: [default_backend: EXLA.Backend]],
  force: true
)
```

## Run SD inference with Nx.Serving

To start, we're going to try to get Stable Diffusion running using `BumbleBee` and `Nx.Serving`. This should (!) be pretty straightforward, we'll use the example notebook [here](https://github.com/elixir-nx/bumblebee/blob/main/notebooks/stable_diffusion.livemd)

```elixir
repository_id = "CompVis/stable-diffusion-v1-4"

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "openai/clip-vit-large-patch14"})

{:ok, clip} = Bumblebee.load_model({:hf, repository_id, subdir: "text_encoder"})

{:ok, unet} =
  Bumblebee.load_model({:hf, repository_id, subdir: "unet"},
    params_filename: "diffusion_pytorch_model.bin"
  )

{:ok, vae} =
  Bumblebee.load_model({:hf, repository_id, subdir: "vae"},
    architecture: :decoder,
    params_filename: "diffusion_pytorch_model.bin"
  )

{:ok, scheduler} = Bumblebee.load_scheduler({:hf, repository_id, subdir: "scheduler"})
{:ok, featurizer} = Bumblebee.load_featurizer({:hf, repository_id, subdir: "feature_extractor"})
{:ok, safety_checker} = Bumblebee.load_model({:hf, repository_id, subdir: "safety_checker"})

:ok
```

```elixir
serving =
  Bumblebee.Diffusion.StableDiffusion.text_to_image(clip, unet, vae, tokenizer, scheduler,
    num_steps: 20,
    num_images_per_prompt: 2,
    safety_checker: safety_checker,
    safety_checker_featurizer: featurizer,
    compile: [batch_size: 1, sequence_length: 60],
    defn_options: [compiler: EXLA]
  )

text_input =
  Kino.Input.text("Prompt", default: "numbat, forest, high quality, detailed, digital art")
```

```elixir
prompt = Kino.Input.read(text_input)

output = Nx.Serving.run(serving, prompt)

for result <- output.results do
  Kino.Image.new(result.image)
end
|> Kino.Layout.grid(columns: 2)
```

That worked! If you got a CuDNN error in the last step (as I did), check your `XLA_TARGET` and make sure you haven't used one with too high a CuDNN. If so, downgrade your `XLA_TARGET` or upgrade CuDNN.
